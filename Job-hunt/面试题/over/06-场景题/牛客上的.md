# ==Java==

## 平时是如何学习java的

- 看书
- 语言是跟计算机沟通的桥梁，所以还会查看jdk等官方文档
- 使用后还要知道底层原理，查资料

## 堆和栈的区别？

- 栈(stack)与堆(heap)都是[Java](http://lib.csdn.net/base/java)用来在Ram中存放数据的地方。与C++不同，Java自动管理栈和堆，程序员不能直接地设置栈或堆

- **功能与作用：**

  - 栈可以看成是方法的运行模型，所有方法的调用都是通过栈帧来进行的，JVM会为每个线程分配一个栈区，以栈帧为单位的压栈和出栈操作。栈帧用于保存当前线程的状态(参数、局部变量、中间计算过程和其他数据)
  -  堆的目的是用于存放对象实例，每个Java应用都唯一对应一个JVM实例，每个JVM实例都唯一对应一个堆，该堆对应的堆内存被应用的所有线程共享。

- **性能与存储：**

  - 栈的性能优于堆，仅次于位于cpu中寄存器。但是在分配内存的时候，存放在栈中的数据大小与生存周期必须在编译时是确定的，缺乏灵活性。
  - 堆可以动态分配内存大小，编译器不必知道要从堆里分配多少存储空间，生命周期也不必事先告诉编译器，Java的垃圾收集器会自动收走这些不再使用的数据，因此可以得到更大的灵活性。但是，由于在运行时动态分配内存和销毁对象都需要占用时间，所以效率低。由于面向对象的多态性，堆内存分配是必不可少的，因为多态变量所需的内存空间，只有在运行时创建对象之后才能确定。当然，为了达到这样的灵活性，必然会付出一定代价！

- **内存分配与回收：**

  - Java中的数据类型有两种：8大基本数据类型、引用类型。
  - 函数中基本类型和对象的引用都是在栈内存中分配。当在一段代码块中定义一个变量时，由于这些变量大小可知，生存期可知，出于追求速度的原因，Java就在栈中为这个变量分配内存空间，当超过变量的作用域后，Java会自动释放掉为该变量所分配的内存空间。
  - 对于引用类型：Java中所有对象的存储空间都是在堆中分配的，但是这个对象的引用却是在堆栈中分配。也就是说在建立一个对象时，从两个地方都分配内存，在堆中分配的内存实际用于建立这个对象，而在栈中分配的内存只是一个指向这个堆对象的引用而已。在堆中分配的内存，由Java虚拟机的自动垃圾回收器来管理

- **内存共享：**

  - 栈数据的内存共享：

    - 假设我们同时定义：int a = 3; int b = 3；编译器先处理int a =3；首先它会在栈中创建一个变量为a的引用，然后查找有没有字面值为3的地址，没找到，就开辟一个存放3这个字面值的地址，然后将a指向3的地址。接着处理int b = 3；在创建完b的引用变量后，由于在栈中已经有3这个字面值，便将b直接指向3的地址。这样，就出现了a与b同时均指向3的情况。

      这种字面值的引用与类对象的引用不同。假定两个类对象的引用同时指向一个对象，如果一个对象引用变量修改了这个对象的内部状态，那么另一个对象引用变量也即刻反映出这个变化。相反，通过字面值的引用来修改其值，不会导致另一个指向此字面值的引用的值也跟着改变的情况。

      如上例，我们定义完a与b的值后，再令a=4；那么，b不会等于4，还是等于3。在编译器内部，遇到a=4时，它就会重新搜索栈中是否有4的字面值，如果没有，重新开辟地址存放4的值；如果已经有了，则直接将a指向这个地址。因此a值的改变不会影响到b的值。
    
  - 引用类型的内存共享：
    
    - 堆中的对象都是独立的，不过对于像

## AQS底层原理

- （ AbstractQueuedSynchronizer ）是一个用来构建锁和同步器（所谓同步，是指线程之间的通信、协作）的框架，Lock 包中的各种锁（如常见的 ReentrantLock, ReadWriteLock）, concurrent 包中的各种同步器（如 CountDownLatch, Semaphore, CyclicBarrier）都是基于 AQS 来构建
- 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中

## new一个对象过程

1、检测类是否被加载
创建一个Java对象时，JVM首先会检查这个new指令的参数能否在常量池中定位到一个类的符号引用，然后检查与这个符号引用相对应的类是否已经成功经历加载、解析和初始化等步骤。如果没有，那必须先执行相应的类加载过程。

2、为新生对象分配内存
当类完成装载步骤之后，就已经完全确定出创建对象实例时所需的内存空间大小，接下来JVM将会对其进行内存分配，以存储所生成的对象实例。在堆中为其开辟内存空间， 在栈中分配一块内存存储变量即引用， 这个变量指向堆内存中得值

3、初始化零值
内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。

4、进行必要的设置
接下来，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象的对象头之中。

5、执行init方法
在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从Java程序的视角来看，对象创建才刚开始，方法还没有执行，所有的字段都还为零。所以一般来说，执行new指令之后会接着执行方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。

## 各代码块的执行顺序

- 执行顺序
  - 父类静态代码块
    子类静态代码块
    父类构造代码块
    父类构造函数
    子类构造代码块
    子类构造函数
- 静态代码块
  - 类中static {}
  - 在类被加载的时候运行，且只执行一次，优先于任何代码块及构造函数。多个静态代码块之间按照书写顺序执行
  - 作用
    - 有些代码需要在项目启动的时候就执行，就会用到静态代码块，比如加载配置文件，我们就可以放入静态代码块。
- 构造代码块
  - 类中{}
  - 在创建对象时调用，每次创建都会调用一次，在构造函数之前执行，它依托于构造函数，如果不实例化对象，构造代码块也不执行
  - 作用
    - 跟踪一些创建对象过程，如统计创建对象的次数
- 构造函数
- 普通代码块
  - 普通代码块和构造代码块的区别在于，构造代码块在类中定义，而普通代码块在方法体中定义。按书写顺序执行

## JMM

- JMM（java内存模型）是什么，JMM定义了一种内存模型来屏蔽各个硬件平台和操作系统的内存访问差异，已实现java程序在各个平台下都能达到一致的内存访问效果

## 原子性、可见性、有序性都是怎么实现的

- 原子性

  - 线程的原子操作是不可被中断的一个或一系列操作，处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。
  - 通过总线锁定保证原子性
    使用处理器提供的lock#信号，当处理器在总线上输出这个信号时，其他处理器的请求会被阻塞住，那么该处理器可以独占共享内存。
  - 通过缓存锁定保证原子性
    通过总线锁定原子性开销比较大，当共享内存被锁定时，其他处理器不能操作其他内存地址的数据。所以处理器在某些场合下使用缓存锁定代替总线锁定。缓存锁定就是处理器不输出lock#信号，而是更改内部的内存地址，使用缓存一致性原则保证操作的原子性
  - java中通过锁和循环CAS保证原子性.。。？

- 可见性

  - 通过同步互斥的方式实现，也就是我们所说的锁。当加锁时，JMM会把该线程对应的本地内存置为无效，从而使得被监视器保护的临界区代码必须从主内存中读取共享内存；当释放锁时，JMM会把线程对应的本地内存中的共享内存刷新到主内存中。
  - 如果觉得加锁的方式过于“重”了，也可以选择使用volatile修饰变量。在写一个volatile变量时，JMM会把线程对应的本地内存中的共享变量刷新到主内存中；在读一个volatile变量时，JMM会把线程对应的本地内存置为无效，线程接下来从主内存中读取共享变量。
  - volatile通过汇编中的lock指令将当前处理器缓存行当数据写回到系统内存，这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。

- 有序性

  - 在单线程下，编译器和处理器会在不改变程序执行结果的前提下，对程序和指令执行顺序进行重新排序，以此优化程序执行效率（这遵守了as-if-serial语义）。但在多线程下，这种重排序会影响程序执行的结果。

    在JMM中，JMM天生具有一定的有序性，这是因为JMM中，如果一个程序的操作执行结果需要对另一个操作可见，那么这两个操作必须要存在happens-before关系（这两个操作可以在单个线程内，也可以在不同的线程之中）。

    as-if-serial语义
    as-if-serial语义的意思是：不管怎么重排序，（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。

    happens-before
    程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作。
    锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作。
    volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作。
    传递规则：如果操作A先行发生于操作B，操作B先行发生于操作C，那么操作A先行发生于操作C。
    线程启动规则：Thread对象的start（）方法先行发生于此线程的每一个动作。
    线程中断规则：对线程interrupt（）方法的调用先行发生于被中断线程的代码检测到中断事件的发生。
    线程终结规则：线程中所有的操作都先行发生于线程的终止检测。
    对象终结规则：一个对象的初始化完成先行发生于它的finalize（）方法的开始。
    两个操作如果不能从happens-before中推断出执行顺序，那么就无法保证它们的有序性。

    重排序
    重排序也被分为

    编译器优化的重排序：编译器在不改变单线程的程序语义的前提下，可以重新安排执行顺序。
    指令级并行的重排序：如果不存在数据依赖性，处理器可以改变语句对应的机器指令都执行顺序。
    内存系统的重排序：由于处理器使用缓存和缓冲区，使得加载和存储操作看上去可能是乱序执行。
    后两种重排序都属于处理器重排序，这三种重排序导致多线程中数据不可见，程序结果不符合预期。我们可以使用volatile和锁这两种方式解决重排序问题，那么从底层开始看起，底层是如何解决重拍序的问题的呢？对于编译器重排序，编译器会禁止特定类型的编译器重排序；对于处理器重排序，会插入特定类型的内存屏障，通过内存屏障禁止特定类型的处理器重排序。


## 说一下RPC的调用流程

​    1.调用者（客户端Client）以本地调用的方式发起调用；
　　2. Client stub（客户端存根）收到调用后，负责将被调用的方法名、参数等打包编码成特定格式的能进行网络传输的消息体；
　　3. Client stub将消息体通过网络发送给服务端；
　　4. Server stub（服务端存根）收到通过网络接收到消息后按照相应格式进行拆包解码，获取方法名和参数；
　　5. Server stub根据方法名和参数进行本地调用；
　　6. 被调用者（Server）本地调用执行后将结果返回给server stub；
　　7. Server stub将返回值打包编码成消息，并通过网络发送给客户端；
　　8. Client stub收到消息后，进行拆包解码，返回给Client；
　　9. Client得到本次RPC调用的最终结果。



## Synchronized和reentrolock具体区别，哪个性能好？各自的适应场景？

- reentrolock性能更好



# ==数据结构==

## 红黑树和AVL的区别是什么

- AVL树：自平衡二叉查找树。每个结点的左右子树的高度之差的绝对值（平衡因子）最多为1。
- 红黑树：平衡二叉查找树的变体，它的左右子树高差有可能大于 1，所以红黑树不是严格意义上的平衡二叉树（AVL），但 对之进行平衡的代价较低， 其平均统计性能要强于 AVL

# ==操作系统==

## 用户态和内核态区别

- 进程的运行级别

- 内核态：

  - 能访问所有的内存空间和对象，且所占有的处理器是不允许被抢占的
  - 能够运行特权指令和非特权指令
  - 特权指令
    - 特只能由操作系统使用、用户程序不能使用的指令。 举例：启动I/O 内存清零 修改程序状态字 设置时钟 允许/禁止终端 停机

- 用户态

  - 进程所能访问的内存空间和对象受到限制，其所处于占有的处理器是可被抢占的
  - 只能够运行非特权指令
  - 非特权指令
    - 用户程序可以使用的指令。 举例：控制转移 算数运算 取数指令 **访管指令**（使用户程序从用户态陷入内核态）

- **用户态--->内核态：**主要途径是通过中断、异常、陷入机制（访管指令）

  - ### 系统调用

    **这是用户态进程主动要求切换到内核态的一种方式**，**用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。**比如前例中fork()实际上就是执行了一个创建新进程的系统调用。

    而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。

    用户程序通常调用库函数，由库函数再调用系统调用，因此有的库函数会使用户程序进入内核态（只要库函数中某处调用了系统调用），有的则不会。

  - ### 异常

    当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

  - ### 外围设备的中断

    **当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号**，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，

    如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

- **内核态--->用户态：**

  - 设置程序状态字PSW

## Java线程和操作系统线程有啥关系

- 内核级线程
  - 在内核级线程中，内核线程建立和销毁都是由操作系统负责、通过系统调用完成的
  - 线程管理的所有工作由内核完成，应用程序没有进行线程管理的代码，只有一个到内核级线程的编程接口. 内核为进程及其内部的每个线程维护上下文信息，调度也是在内核基于线程架构的基础上完成
  - 优点
    - 多处理器系统中，内核能够并行执行同一进程内的多个线程
    - 如果进程中的一个线程被阻塞，能够切换同一进程内的其他线程继续执行（用户级线程的一个缺点）
    - 所有能够阻塞线程的调用都以系统调用的形式实现，代价可观
    - 当一个线程阻塞时，内核根据选择可以运行另一个进程的线程，而用户空间实现的线程中，运行时系统始终运行自己进程中的线程
    - 信号是发给进程而不是线程的，当一个信号到达时，应该由哪一个线程处理它？线程可以“注册”它们感兴趣的信号
- 用户级线程
  - 有关线程管理的所有工作都由应用程序完成，内核意识不到线程的存在. 应用程序可以通过使用线程库设计成多线程程序
  - 用户级线程仅存在于用户空间中，此类线程的创建、撤销、线程之间的同步与通信功能，都无须利用系统调用来实现
  - 优点
    - 可以在不支持线程的操作系统中实现。
    - 创建和销毁线程、线程切换代价等线程管理的代价比内核线程少得多, 因为保存线程状态的过程和调用程序都只是本地过程
    - 允许每个进程定制自己的调度算法，线程管理比较灵活。这就是必须自己写管理程序，与内核线程的区别
    - 线程能够利用的表空间和堆栈空间比内核级线程多
    - 不需要陷阱，不需要上下文切换，也不需要对内存高速缓存进行刷新，使得线程调用非常快捷
    - 线程的调度不需要内核直接参与，控制简单。
  - 缺点
    - 线程发生I/O或页面故障引起的阻塞时，如果调用阻塞系统调用则内核由于不知道有多线程的存在，而会阻塞整个进程从而阻塞所有线程, 因此同一进程中只能同时有一个线程在运行
    - 页面失效也会产生类似的问题。
    - 一个单独的进程内部，没有时钟中断，所以不可能用轮转调度的方式调度线程
    - 资源调度按照进程进行，多个处理机下，同一个进程中的线程只能在同一个处理机下分时复用
- 组合型
  - n个用户线程：m个内核线程
  - 使用组合方式的多线程实现, 线程创建完全在用户空间中完成，线程的调度和同步也在应用程序中进行. 一个应用程序中的多个用户级线程被映射到一些（小于或等于用户级线程的数目）内核级线程上
- 用户级别线程和内核级别线程的区别
  - 内核支持线程是OS内核可感知的，而用户级线程是OS内核不可感知的。
  - 用户级线程的创建、撤消和调度不需要OS内核的支持，是在语言（如Java）这一级处理的；而内核支持线程的创建、撤消和调度都需OS内核提供支持，而且与进程的创建、撤消和调度大体是相同的。
  - 用户级线程执行系统调用指令时将导致其所属进程被中断，而内核支持线程执行系统调用指令时，只导致该线程被中断。
  - 在只有用户级线程的系统内，CPU调度还是以进程为单位，处于运行状态的进程中的多个线程，由用户程序控制线程的轮换运行；在有内核支持线程的系统内，CPU调度则以线程为单位，由OS的线程调度程序负责线程的调度。
  - 用户级线程的程序实体是运行在用户态下的程序，而内核支持线程的程序实体则是可以运行在任何状态下的程序。

## socker传输过程

## 进程，线程区别

- **进程与线程的区别总结**

  线程具有许多传统进程所具有的特征，故又称为轻型进程(Light—Weight Process)或进程元；而把传统的进程称为重型进程(Heavy—Weight Process)，它相当于只有一个线程的任务。在引入了线程的操作系统中，通常一个进程都有若干个线程，至少包含一个线程。

  根本区别：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位

  资源开销：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。

  包含关系：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。

  内存分配：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的

  影响关系：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。

  执行过程：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行.

# ==网络==

## tcp可以看见https加密前的明文吗

- 不能，还没有进行解密
- 加密层位于http层（应用层）和tcp层（传输层）之间， 所以抓到的http层的数据并没有加密。
- HTTPS是通过一次非对称加密算法（如RSA算法）进行了协商密钥的生成与交换，然后在后续通信过程中就使用协商密钥进行对称加密通信，之所以要使用这两种加密方式的原因在于非对称加密计算量较大，如果一直使用非对称加密来传输数据的话，会影响效率。

## Servlet重要方法

- 实例化-------Servlet 容器创建 Servlet 的实例

- 初始化-------该容器调用 init ( ServletConfig ) 方法

- 服务------如果请求 Servlet，则容器调用 service() 方法

- 销毁-------销毁实例之前调用 destroy() 方法

  


## TCP 四次挥手有个 TIME_WAIT 状态你知道吗？这个状态是在哪一端的？为什么要有这个状态？

- 主动断开的那一方就会进入 TIME_WAIT 状态，状态持续 2 个 MSL（Max Segment Lifetime）

- 背景

  - IP 报文头中有一个 8 位的存活时间字段（Time to live, TTL），是一个 IP 报文最大可经过的路由数，每经过一个路由器，TTL 减 1，当 TTL 减到 0 时这个 IP 报文会被丢弃
  - MSL：类似于TTL，不过不是跳数，用的是事件。最大跳数的报文在网络中存活的时间

- 为什么要这个状态

  - **数据报文可能在发送途中延迟但最终会到达，因此要等老的“迷路”的重复报文段在网络中过期失效，这样可以避免用相同源端口和目标端口创建新连接时收到旧连接姗姗来迟的数据包，造成数据错乱**。**等待时间是 2 个 MSL，已经足够让一个方向上的包最多存活 MSL 秒就被丢弃，保证了在创建新的 TCP 连接以后，老连接姗姗来迟的包已经在网络中被丢弃消逝，不会干扰新的连接。**

  - **确保可靠实现 TCP 全双工终止连接。**

    关闭连接的四次挥手中，最终的 ACK 由主动关闭方发出，如果这个 ACK 丢失，对端（被动关闭方）将重发 FIN，如果主动关闭方不维持 TIME_WAIT 直接进入 CLOSED 状态，则无法重传 ACK，被动关闭方因此不能及时可靠释放

## 那你听过 RSA 和 AES 吗？

## 比如说你刚刚讲到的非对称和对称加密，它们分别使用的是什么算法了解吗？

- https://www.baidu.com/link?url=TQNKhJrsLXxs-xe9Ougczeap2nQhiT7zwoL4duBSJJTvoVGL-MyPCLYVAwF-6K4nLuoiMXuVMkiu7YoGQ1XqS_&wd=&eqid=b9de9a67000c733200000005643bff2c

- 加密算法

  - **加密算法**根据内容是否可以还原分为可逆加密和非可逆加密。
  - **可逆加密**根据其加密解密是否使用的同一个密钥而可以分为对称加密和非对称加密。

- **对称加密算法**

  - **对称加密**是指在加密和解密时使用同一个密钥。
  - 优点：速度快，适合加密大量数据。
    缺点：密钥的传递存在着安全隐患，若在网络上传输，密钥泄露，则消息内容泄露。
    常见算法：AES、DES、3DES，国密SM4

- **非对称加密算法**

  - **非对称加密算法**是由一对密钥来进行加解密的过程，分别称为**公钥**和**私钥**。该加密算法的原理就是**对一极大整数做因数分解的困难性**来保证安全性。

  - 分发公钥给别人，自己使用私钥，只有私钥可以解密。

  - 优点：非对称加密与对称加密相比，其安全性更好，可以避免秘钥在传递过程中泄露。
    缺点：加密和解密花费时间长、速度慢，只适合对少量数据进行加密。
    算法过程：B是发送方，A是接收方，A、B都有各自的公钥和私钥，B使用A的公钥对信息进行加密传输，A收到密文后使用A的私钥解开。
    常见算法：RSA、ECC，国密SM2

    B用A发的公钥用于数据加密，A用自己的私钥进行解

  - **（签名/验签）**

    上述非对称加密方式看起来，安全性上似乎完美。但是实际上存在一个问题。

    公钥是公开的，任何人可以获取，那就意味着，除了B、C、D以外的其他人，可以轻易拿到公钥，传递虚假消息给A，A却无法分辨消息的真实。

    所以，在非对称加密的基础上进行了改进，解决密文在传输过程中可能会被篡改的问题。

    那就是对消息内容进行数字签名，证明这个数据的来源是B/C/D。

    过程

    ​	  B用自己的私钥对摘要信息进行签名，A用B分发的公钥进行验证

    其实是A和B都有自己的私钥和公钥

- **Hash算法**

  **单向算法，密文长度固定**

  Hash算法特别的地方在于它是一种单向算法，用户可以通过hash算法对目标信息生成一段特定长度的唯一hash值，却不能通过这个hash值重新获得目标信息。
  
  因此Hash算法常用在不可还原的密码存储、信息完整性校验等。
  
  Hash算法是不可逆的，而其他加密算法是可逆的。
  
  常见的Hash算法：MD2、MD4、MD5、SHA、SHA-1、HMAC、HMAC-MD5、HMAC-SHA1、RIPEMD160，国密SM3
  
- 

-   **各种加密算法**

  ***\*5.1\** 对称加密算法：DES/3DES/\**AES\****

  DES、3DES、AES 都是 **对称** 的 **块加密算法**，加解密 的过程是 **可逆**的。常用的有 AES128、AES192、AES256 。
  
  **DES算法**
  
  DES 加密算法是一种 **分组密码**，以 64 位为分组对数据加密，它的**密钥长度**是 56 位，加密解密用同一算法。
  
  DES 加密算法是对 **密钥** 进行保密，而 公开算法，包括加密和解密算法。这样，只有掌握了和发送方 相同密钥 的人才能解读由 DES加密算法加密的密文数据。因此，破译 DES 加密算法实际上就是 搜索密钥的编码。对于 56 位长度的 密钥 来说，如果用 穷举法 来进行搜索的话，其运算次数为 2 ^ 56 次。
  
  **3DES算法**
  
  是基于 DES 的 **对称算法**，对 一块数据 用 **三个不同的密钥** 进行 **三次加密**，强度更高。
  
  **AES算法**
  
  AES 加密算法是密码学中的 高级加密标准，该加密算法采用 **对称分组密码体制**，密钥长度的最少支持为 128 位、 192 位、256 位，分组长度 128 位。
  
  AES 本身就是为了取代 DES 的，AES 具有更好的 **安全性**、**效率** 和 **灵活性**。
  
   
  
  ***\*5.2\** 非对称加密算法：RSA/ECC**
  
  **RSA算法**
  
  RSA 加密算法是目前最有影响力的 **公钥加密算法**，并且被普遍认为是目前 最优秀的公钥方案 之一。RSA 是第一个能同时用于 **加密** 和 **数字签名** 的算法，它能够 抵抗 到目前为止已知的 所有密码攻击，已被 ISO 推荐为公钥数据加密标准。
  
  **ECC算法**
  
  ECC 也是一种 **非对称加密算法**，主要优势是在某些情况下，它比其他的方法使用 **更小的密钥**。不过一个**缺点**是 **加密和解密操作** 的实现比其他机制 **时间长** (相比 RSA 算法，该算法对 **CPU消耗严重**)。
  
   
  
  ***\*5.3\** Hash算法：MD5/SHA1**
  
  **MD5算法**
  
  MD5 用的是哈希函数，它的典型应用是对一段信息产生 **信息摘要**，用于确保文件内容的完整一致性，以**防止被篡改**。严格来说，MD5 不是一种 加密算法而是**摘要算法**。
  
  无论是多长的输入，MD5 都会输出长度为 128bits 的一个串 (通常用 16 进制 表示为 32 个字符)。
  
  **SHA1算法** 
  
  SHA1 是和 MD5 一样流行的 **消息摘要算法**，然而 SHA1 比 MD5 的 **安全性更强**。对于长度小于 2 ^ 64 位的消息，SHA1 会产生一个 160 位的 消息摘要。基于 MD5、SHA1 的信息摘要特性以及 **不可逆** (一般而言)，可以被应用在检查 **文件完整性** 以及 **数字签名** 等场景。
  

**6.4.1 对称\**加密\**算法**

1. 密钥管理：比较难，不适合互联网，一般用于内部系统
2. 安全性：中
3. 加密速度：快几个数量级 (软件加解密速度至少快 100 倍，每秒可以加解密数 M 比特 数据)，适合**大数据量**的加解密处理

**6.4.2 非对称\**加密\**算法**

1. 密钥管理：密钥容易管理
2. 安全性：高
3. 加密速度：比较慢，适合 **小数据量** 加解密或数据签名

## TCP头部为什么比UDP长，具体哪些字段 

- udp
  - 源端口
  - 目的端口
  - 长度：整个数据报的长度
  - 检验和：整个数据报的检验和。
- tcp
  - 源端口 和 目的端口
    传输层和网络层一大重要区别就是传输层指定了数据报发往的应用进程，因此需要端口号标识。
  - 序号
    当前TCP数据报数据部分的第一个字节的序号。我们知道，TCP是面向字节的，它会对发送的每一个字节进行编号，而且不同数据报之间是连续编号的。
    由于本字段4字节，可以给[0,232-1]个字节进行编号（大约4G），而且序号循环使用，当发送完232-1个字节后，序号又从0开始。一般来说，当2^32-1个字节被发送的时候，前面的字节早就发送成功了，因此序号可以循环使用。
  - 确认号
    表示当前主机作为接收端时，期望接收的下一个字节的编号是多少。也表示，当前主机已经正确接收的最后一个字节序号+1。
  - 数据偏移（报文长度）
    它表明了数据报头部的长度。
  - 保留字段
  - 标识符
    TCP有7种标识符，用于表示TCP报文的性质。它们只能为0或1。
    - URG=1 当URG字段被置1，表示本数据报的数据部分包含紧急信息，此时紧急指针有效。紧急数据一定位于当前数据包数据部分的最前面，紧急指针标明了紧急数据的尾部。如control+c：这个命令要求操作系统立即停止当前进程。此时，这条命令就会存放在数据包数据部分的开头，并由紧急指针标识命令的位置，并URG字段被置1。

    - ACK=1 ACK被置1后确认号字段才有效。此外，TCP规定，在连接建立后传送的所有报文段都必须把ACK置1。

    - PSH=1 当接收方收到PSH=1的报文后，会立即将数据交付给应用程序，而不会等到缓冲区满后再提交。一些交互式应用需要这样的功能，降低命令的响应时间。
    - RST=1 当该值为1时，表示当前TCP连接出现严重问题，必须要释放重连。
    - SYN=1 SYN在建立连接时使用。当SYN=1，ACK=0时，表示当前报文段是一个连接请求报文。当SYN=1，ACK=1时，表示当前报文段是一个同意建立连接的应答报文。

    - FIN=1 FIN=1表示此报文段是一个释放连接的请求报文。
  - 接收窗口大小
    该字段用于实现TCP的流量控制。它表示当前接收方的接收窗口的剩余容量，发送方收到该值后会将发送窗口调整成该值的大小。发送窗口的大小又决定了发送速率，所以接收方通过设置该值就可以控制发送放的发送速率。发送方每收到一个数据报都要调整当前的发送窗口
  - 检验和
    用于接收端检验整个数据包在传输过程中是否出错。
  - 紧急指针
    用于标识紧急数据的尾部。
  - 选项字段
    上述字段都是每个TCP头部必须要有的，而选项字段是可选的，且长度可变，最长40字节。 最常用的选项字段为MMS：最大报文长度。

# ==Mysql==

## MySQL 哪些情况下不建议使用索引

- 数据量少
- 经常进行一些索引失效的查询
- 更新频繁

## 数据库索引为字段（a，b，c），请问查询哪些字段能命中索引

- a = 1 AND b = 2 AND c = 3 ; 使用索引
  c = 1 AND b = 2 AND a = 3 ; 使用索引 
  a = 1 AND b = 2 ; 使用索引
  a = 1 AND c = 3 ; 使用索引
  c = 1 AND a = 2 ; 使用索引

- **不包含最左侧的 a 的不使用索引**

- **OR 不使用索引**

- **最左侧的‘a’列 被大于，小于，不等于比较的 ，使用range索引**

- a = 1 AND b < 2 AND c = 3 使用索引
  a = 1 AND c = 2 AND b < 3 使用索引
  a = 1 AND b < 2 使用索引
  a = 1 AND b <> 2 AND c = 3 使用索引
  // 可以说 OR一出现就不使用
  a = 1 AND b < 2 OR c = 2 未使用索引

- 1) MySQL联合索引遵循最左前缀匹配规则，即从联合索引的最左列开始向右匹配，直到遇到匹配终止条件。例如联合索引(col1, col2, col3), where条件为col1=a AND col2=b可命中该联合索引的(col1,col2)前缀部分, where条件为col2=b AND col3=c不符合最左前缀匹配，不能命中该联合索引。

  2) 匹配终止条件为范围操作符(如>, <, between, like等)或函数等不能应用索引的情况。例如联合索引(col1, col2, col3), where条件为col1=a AND col2>1 AND col3=c, 在col2列上为范围查询，匹配即终止，只会匹配到(col1, col2)，不能匹配到(col1, col2, col3).

  3) where条件中的顺序不影响索引命中。例如联合索引(col1, col2, col3), where条件为col3=c AND col2=b AND col1=a, MySQL优化器会自行进行优化，可命中联合索引(col1, col2, col3).



# ==Redis==



## 你了解一些限流的设计思路吗？

- 限流 模式

  - 熔断
    - 将熔断措施嵌入到系统设计中，当系统出现问题时，若短时间内无法修复，系统会自动开启熔断开关，拒绝流量访问，避免大流量对后端的过载请求。
  - 降级
    - 将系统的所有功能服务进行一个分级，当系统出现问题需要紧急限流时，可将不是那么重要的功能进行降级处理，停止服务，保障核心功能正常运作。
    - 例如在电商平台中，如果突发流量激增，可临时将商品评论、积分等非核心功能进行降级，停止这些服务，释放出机器和 CPU 等资源来保障用户正常下单。
  - 延迟处理
    - 延迟处理需要在系统的前端设置一个流量缓冲池，将所有的请求全部缓冲进这个池子，不立即处理。后端真正的业务处理程序从这个池子中取出请求依次处理，常见的可以用队列模式来实现
  - 特权处理
    - 这个模式需要将用户进行分类，通过预设的分类，让系统优先处理需要高保障的用户群体，其它用户群的请求就会延迟处理或者直接不处理

- 限流算法

  - 计数器法

    - 计数器算法是限流算法中最简单最容易的一种，如上图每分钟只允许100个请求，第一个请求进去的时间为startTime，在startTime + 60s内只允许100个请求 。

      当60s内超过十个请求后，则拒绝请求；不超过的允许请求，到第60s 重新设置时间。

  - 滑动窗口

    - 在计数器算法限流的例子中，一个时间窗口就是一分钟。在这里将时间窗口进行划分，比如图中，将滑动窗口划成了6格，每格代表的是10秒钟。每过10秒钟，时间窗口就会往右滑动一格。每一个格子都有自己独立的计数器counter，
    - 计数器算法其实就是滑动窗口算法。只是它没有对时间窗口做进一步地划分，所以只有1格。所以，当滑动窗口的格子划分得越多，则滑动窗口的滚动就越平滑，限流的统计就会越精确

  - 漏桶算法

    - 漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会超过桶可接纳的容量时直接溢出，可以看出漏桶算法能强行限制数据的传输速率。

  - 令牌桶算法

    - 以固定速率产生令牌，放入令牌桶，每次用户请求都得申请令牌，令牌不足则拒绝请求或等待。

- 分布式限流

  - 比如为了限制某个资源被每个用户或者商户的访问次数，5s只能访问2次，或者一天只能调用1000次，这种场景单机限流是无法实现的，这时就需要通过集群限流进行实现。
  - 只需要拼接用户id和接口名，加上当前服务名的前缀作为redis的key，每次该用户访问此接口时，只需要对这个key执行incr命令，再这个key带上过期时间，就可以实现指定时间的访问频率。

# ==SSM==

## AOP和IOC

- IOC控制反转是一种设计思想，将原本在程序中手动创建对象的控制权，交由Spring框架来管理。

  IOC的思想最核心的地方在于，`资源不由使用资源的双方管理，而由不使用资源的第三方管理`。这可以带来很多好处：

  - 资源集中管理，实现资源的可配置和易管理
  - `降低了使用资源双方的耦合度`

- AOP面向切面编程。能够将那些与业务无关，**却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来**，便于**减少系统的重复代码**，**降低模块间的耦合度**，并有利于未来的可拓展性和可维护性。

  使用AOP可以把一些通用功能抽象出来，在需要用到的地方直接使用即可，这样大大简化了代码量。我们需要增加新功能时也方便，这样也提高了系统扩展性。日志功能、事务管理等场景都用到了AOP

  利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的`耦合度降低`，提高程序的可重用性，同时提高了开发效率。

  专业术语
          1.Advice （增强/通知） 表示需要扩展的功能，所在的类叫做增强类/通知类。

  ​		2.JoinPoint（连接点）程序执行的某个特定位置

  ​		3.PointCut（切入点）AOP 通过切点来定位特定的连接点

  ​		4.Aspect（切面）切面由切点和增强组成，他既包含横切的定义，也包括了连接点的定义。 springAOP就是负责实施切面的框架，他将切面定义为横切逻辑织入到切面所指定的连接点。

  ​		5.织入(weaving) 就是把Advice添加到目标类的连接点的过程

  ​		6.目标对象 顾名思义：要增强到具体的对象



## 谈一谈aop中的设计模式。

- 代理模式

# ==Linux==

## Linux哪个命令可以查看端口被哪个应用占用？

- lsof -i :8080           查看具体端口被哪个程序占用
- **sudo ss -tlnp | grep 端口号**         列出当前系统中打开的套接字(socket)信息
-  netstat -anp | grep 8080        查看已知端口占用情况

## 了解僵尸进程吗？

- 僵尸进程是指一个已经终止、但是其父进程尚未对其进行善后处理获取终止进程的有关信息的进程，这个进程被称为“僵尸进程”(zombie)。

- 怎样产生僵尸进程

   一个进程在调用exit命令结束自己的生命的时候，其实它并没有真正的被销毁，而是留下一个称为[僵尸进程](http://www.nowamagic.net/librarys/veda/tag/僵尸进程)（Zombie）的数据结构（系统调用exit， 它的作用是使进程退出，但也仅仅限于将一个正常的进程变成一个僵尸进程，并不能将其完全销毁）。

  在Linux进程的状态中，僵尸进程是非常特殊的一种，它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程列表中保留一个位 置，记载该进程的退出状态等信息供其他进程收集。除此之外，僵尸进程不再占有任何内存空间。它需要它的父进程来为它收尸，如果他的父进程没安装 SIGCHLD 信号处理函数调用wait或waitpid()等待子进程结束，又没有显式忽略该信号，那么它就一直保持僵尸状态，如果这时父进程结束了， 那么init进程自动会接手这个子进程，为它收尸，它还是能被清除的。但是如果如果父进程是一个循环，不会结束，那么子进程就会一直保持僵尸状态，这就是 为什么系统中有时会有很多的僵尸进程。

- 僵尸进程问题及危害
  unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息，就可以得到。

  这种机制就是: 在每个进程退出的时候,内核释放该进程所有的资源,包括打开的文件,占用的内存等。

  但是仍然为其保留一定的信息(包括进程号 the process ID,退出状态 the termination status of the process,运行时间 the amount of CPU time taken by the process 等)。直到父进程通过 wait / waitpid 来取时才释放。

  但这样就导致了问题，如果进程不调用 wait / waitpid 的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免

- 怎么查看僵尸进程

  利用命令ps，可以看到有父进程ID为1的进程是孤儿[进程](http://www.nowamagic.net/librarys/veda/tag/进程)；s(state)状态为Z的是僵尸进程。

  注意：孤儿进程(orphan process)是尚未终止但已停止(相当于前台挂起)的进程，但其父进程已经终止，由init收养；而僵尸进程则是已终止的进程，其父进程不一定终止。

- 怎样来清除僵尸进程

1. 改写父进程，在子进程死后要为它收尸。具体做法是接管SIGCHLD信号。子进程死后， 会发送SIGCHLD信号给父进程，父进程收到此信号后，执行 waitpid()函数为子进程收尸。这是基于这样的原理：就算父进程没有调用wait，内核也会向它发送SIGCHLD消息，尽管对的默认处理是忽略， 如果想响应这个消息，可以设置一个处理函数。
2. 把父进程杀掉。父进程死后，僵尸进程成为"孤儿进程"，过继给1号进程init，init始终会负责清理僵尸进程，关机或重启后所有僵尸进程都会消失。

- 避免Zombie Process的方法

1. 在SVR4中，如果调用signal或sigset将SIGCHLD的配置设置为忽略,则不会产生僵死子进程。另外,使用SVR4版的 sigaction,则可设置SA_NOCLDWAIT标志以避免子进程僵死。 Linux中也可使用这个，在一个程序的开始调用这个函数signal(SIGCHLD,SIG_IGN)。
2. 调用fork两次。
3. 用waitpid等待子进程返回。

## Linux命令实现：统计文件中某个字符串的个数

- grep -o '字符串' 文件名 | wc -l

# ==项目==

## 介绍一下项目吧

- 项目定位

  - 为用户提供了一个分享生活的平台

- 项目背景

  - 社交是人类生活中必不可少的一部分，在快节奏生活下的年轻人，学习工作之余经常会倍感孤单，但又苦于身边圈子小，线下社交社恐等
  - 陌生人社交App成为大家消遣时间的最佳选择。与之相比的是QQ空间和微信朋友圈等熟人社交平台反而冷清些，因为熟人社交的话题总是有限的。
- 社交的一大前提是信息共享，所以基于笔记分享的开放式平台在未来市场依旧会有很大份额
  - 笔记不指定特定的主题

- 项目优势

  - 分享来源于生活，社交属性强，用户黏性高
  - 可扩展性强，如后续可以将社交与电商融合，为用户提供更好的购物体验
  - 内容为本，用户都更喜欢令人眼前一亮的优质作品，同质化的非原创内容会逐步迈进“审美疲劳”陷阱，而基于笔记分享的形式，用户可以做到随想随发，这样的作品往往最具有创作性

- 发展前景

  - 积极拓展海外市场，进一步扩大了其的用户群体和商业价值

## 你这个项目有用起来吗？做这个项目的意义是什么？现在到什么阶段了

## 那你展开聊一下这个项目吧

## 项目难点可以展开说说吗，以及怎么解决的

- 上传头像等数据时响应慢
  - 在用户上传头像这里。分为三步：用户提交头像->服务器收到头像->服务器将头像上传到云存储

  - 用户上传头像到服务器时，我们认为这次上传即为成功。那么应该立即返回结果
  - 而第三步上传云存储费事比较久，大概要十几秒，这个时间不应该由用户等待，出错也不应该由用户承担，
  - 所以用额外一个线程用于这第三步

## 技术亮点可以说说吗

- 架构
  - 微服务

- 单点登陆
  - 问题
    - 将项目划分为多个微服务模块了，每次访问不同的服务都要登陆
  - 解决
    - 登陆的时候将cookie存放到redis中，并返回给用户
    - 在网关通过全局过滤器来判断是否redis中是否有值，有则放行，没有则跳转到登陆

- 热点数据存缓存
  - 问题
    - 当用户请求如阅读量等高频数据的时候，持续访问数据库造成数据库压力过大
  - 解决
    - 对于这部分数据，在数据库查询到后，放到Redis中来
    - 由于阅读量变化频率比较快，在允许弱一致性的情况下，每次都更新Redis，过一段时间再更新数据库

- 云存储
  - 问题
    - 用户头像、笔记图片、视频等数据如果用本地存储的话，当数据增多的时候，磁盘空间会不够
  - 解决
    - 使用云存储，把数据上传到云服务器。
    - 在项目中用的是工厂模式，可获取不同的云存储服务
    - 相较于传统文件存储，云存储能够实现规模效应和弹性扩展，降低运营成本，避免资源浪费。
    - 只需要简单的api就能方便的访问，不与本地应用粘合在一起，降低了程序间的耦合度

## 给你一个项目你会从哪方面考虑

- 需求分析
  - 明确客户的要求是什么
- 成本计算
  - 分析项目需要的人力物力，技术等
  - 以便后续协调开发
- 开发模式选择
  - 原型模式，能够很快提供一个可运行的方案。
  - 然后在该模型上不断增加功能
- 开发
  - 扩展性要好
  - 性能（缓存
  - 并发（集群
  - 容错性（主从，数据备份
  - 安全验证（黑客攻击
  - 限流
  - 解耦（mq
- 测试
- 文档

## 项目中用过哪些设计模式？

- 单例模式
- 简单工厂模式（其实不算

# ==场景==

## 想要实现一个100qps的限流策略，怎么从后端进行设计

- 令牌桶
- redis

## 4g大小的文本，统计单词的个数

- 总体思路
  - 首先，将文本切分成多个小文件，每个小文件大小适中，比如 100MB。将这些小文件分别分配到多台计算机上进行处理。
  - 在每台计算机上，使用多线程读取小文件中的内容，将单词拆分出来，并将每个单词作为 key，对应的出现次数作为 value 存储到本地内存中的一个 hash map 中。
  - 当一个小文件被处理完成后，将这个 hash map 中的所有单词出现次数合并到一个全局的 hash map 中。这个全局的 hash map 可以存储在一个共享的存储系统中，比如 Redis。
  - 所有小文件处理完成后，最终得到的全局 hash map 就是每个单词在整个文章中出现的次数了。
- 技术思考
  - 数据的处理方式：对于10G这样的大数据，通常无法一次性加载到内存中进行处理。因此，我们需要考虑如何对数据进行分块、分批次加载、并发处理等方面的优化，以提高处理效率和准确性。
  - 哈希算法的选择：哈希算法是单词计数的关键，它决定了单词计数的准确性和效率。对于大数据，哈希算法的性能和冲突率都是需要考虑的因素。我们可以使用一些优秀的哈希算法，如MurmurHash、CityHash等，以及优秀的哈希算法库，如Google的FarmHash、SpookyHash等。
  - 并行计算的优化：在多核CPU和分布式计算环境下，我们可以考虑并行计算的优化，以充分利用计算资源提高计算效率。例如可以使用并发编程框架，如Java的Fork/Join框架、Hadoop、Spark等，并结合分布式文件系统、分布式数据库等技术，提高处理速度。
  - 算法的优化：除了哈希算法外，我们还可以考虑其他算法的优化。例如可以使用Trie树、倒排索引等数据结构，提高单词查找的速度和准确性。
  - 系统资源的管理：在处理大数据时，系统资源的管理也是非常重要的一环。例如可以优化JVM的内存管理、设置GC策略、合理利用操作系统的缓存等，以提高系统的稳定性和处理效率。
- 关联思考
  - 处理大规模文本数据的数据结构和算法：对于大量文本数据的处理，需要选择适当的数据结构和算法来优化性能。例如，可以使用 Bloom Filter 来减少单词哈希冲突的概率，使用多线程处理数据以提高处理速度。
  - 存储和处理大规模文本数据的工具和技术：处理超过10G的文本数据需要使用到大规模数据存储和处理的工具和技术。例如，可以使用 Hadoop、Spark 等分布式计算框架来处理大规模数据，使用 Redis、HBase 等分布式存储系统来存储数据。
  - 处理文本数据的语言处理技术：在文本数据处理中，可以应用一些自然语言处理技术来处理文本数据。例如，可以使用分词、词性标注等技术来处理单词，并使用词向量、主题模型等技术来分析文本数据。
  - 数据质量和准确性：在处理大规模文本数据时，需要考虑数据质量和准确性的问题。例如，需要处理缺失数据、重复数据、错误数据等问题。可以使用数据清洗和预处理技术来提高数据质量和准确性。
    

## 管理云上主机数500万，数据2G，查询请求1000万/s，更新请求1000/s，如何设计该模块？



# ==脑筋急转弯==

## 五人过河问题

## 有两根不均匀分布的香,香烧完的时间是一个小时,你能用什么方法来确定一段15分钟的时间?



# ==微服务==

## 微服务调用openfeign底层怎么调用的原理

## 你对云原生的技术栈有一些了解吗？

## 为什么用微服务来部署整个业务，它和传统架构的区别是什么，优缺点分别是什么

- 传统单体架构

  - 优点
    - 易于开发和部署
      单体架构的应用程序一直存在。许多工具确实促进了简单的开发和部署策略。开发人员需要执行一块可部署的代码，而不是在单独的实体中进行更新。
    - 高性能
      单体应用相比于微服务有着更好的性能，这也是单体应用的关键优势。基于微服务的应用程序可能需要对 100 个其他微服务进行 100 次不同的 API 调用才能加载一个 UI 屏幕。而在单体应用中，一个 API 调用可以达到相同的目的，因为它具有集中的代码和内存。

- 微服务

  - 一种软件开发技术- 面向服务的体系结构（SOA）架构样式的一种变体，它提倡将单一应用程序划分成一组小的服务，服务之间互相协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务间采用轻量级的通信机制互相沟通（通常是基于HTTP的RESTful API）。每个服务都围绕着具体业务进行构建，并且能够独立地部署到生产环境、类生产环境等。另外，应尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据上下文，选择合适的语言、工具对其进行构建。

  - 优点

    - 更好的组织
      由于整个代码库被分解为更小的服务，组织起来相对单体架构更好。微服务有特定的工作，不依赖于其他组件。
    - 敏捷性高
      使用微服务，团队中的个人可以处理单个模块。每个人都可以独立构建模块和部署模块，从而减少团队的运维摩擦，提高软件交付的敏捷性。
  - 更广泛的技术选型
  
- 缺点
  
    -  需要对原有的系统进行微服务划分
    - 数据一致性、微服务的数据库不同。
  - 沟通成本，如果api改变，如果想修改就需要别的团队联合修改
  
- 分布式要考虑的问题
  
  - 性能  由于是跨进程跨网络的调用，因此必须要考虑网络延迟以及带宽带来的影响
  
    尤其是多个服务相互协作时，响应时间及性能对系统的影响
  
  - 可靠性 由于网络，带宽，节点等自身可靠性因素的影响，任何一次组件间的远程调用，都可能失败，且微服务数量很多时，潜在更多的单点故障，所以 保证系统的可靠性，降低由于网络，组件引起的单点故障率，也成了构建系统的挑战
  
  - 异步  由于夸网络调用，需要考虑异步的通信机制，这样出现问题时的调试就会变得很麻烦
  
    - 数据一致性 为了保证数据一致性，我们通常考虑分布式事务管理，但是它会涉及到跨多个节点来保证数据的瞬时一致性，比起传统的事务成本就会高很多，通常，也会用最终的数据一致性来解决数据瞬时一致带来的系统不可用

# ==个人（HR）==

## HR面本质



## 自己性格的优缺点

- 做事很有计划性

- 能够很好接受新事物
- 喜欢做笔记，

- 我总是希望付出能有收获，若是做一件事多次到最后还是没有成功，那我可能会产生一些焦虑
- 我觉得在战略思维方面，还要加强学习，继续改进

## 未来的职业规划

- 好的，我很早就考虑过未来的职业发展，并且已经有了明确的职业规划。下面是我未来三年的规划
- 并计划在秋招后完成更细致的底层原理的学习，和提高算法思维，同时去深入前沿知识，如微服务，云原生等技术栈。
- 在工作的第一年，认真细致地完成我的本职工作，学习前辈们的经验，在项目中锻炼自己的各方面的能力。如怎么设计软件架构，怎么协调和同事的工作，怎么组织和领导一个团队等
- 在工作的第二年，若能力达标，抓住晋升的机会，带领小团队进行开发。
- 我本身很热爱编程工作，也在Java方面积累了专业知识，所以，未来会继续从事后端开发岗位。在我看来，选择了互联网这个日新月异的行业，无论我在哪工作，终身学习都是必要的。

## 简历上的个人评价怎么理解

## 为什么选择菜鸟

## 你坚持得最久的一件事是什么，它给你带来了什么影响？

- 自学。

## 你的优势和劣势

# ==反问==

## 部门的技术栈

## 可以给我一些建议吗

## 面试的整体流程



# ==算法==

## 202.快乐数

- HashSEt：时间复杂度O(lgn)，空间复杂度O(lgn)

  ```java
  class Solution {
      //可能在后面成环，所以不能只判断开头
      public boolean isHappy(int n) {
          HashSet<Integer>set=new HashSet<>();
          set.add(n);
          while(n!=1){
              int t=0;
              while(n!=0){
                  t+=(int)Math.pow(n%10,2);
                  n/=10;
              }
              n=t;
              if(n!=1 && set.contains(n)){
                  return false;
              }
              set.add(n);
          }
          return true;
      }
  }
  ```

- 快慢指针判断是否有环：时间复杂度O(lgn)   空间复杂度O(1)

  ```java
  class Solution {
  
       public int getNext(int n) {
          int totalSum = 0;
          while (n > 0) {
              int d = n % 10;
              n = n / 10;
              totalSum += d * d;
          }
          return totalSum;
      }
  
      public boolean isHappy(int n) {
          int slowRunner = n;
          int fastRunner = getNext(n);
          while (fastRunner != 1 && slowRunner != fastRunner) {
              slowRunner = getNext(slowRunner);
              fastRunner = getNext(getNext(fastRunner));
          }
          return fastRunner == 1;
      }
  }
  
  ```

# ==总结==

## 没有项目的八股就是无源之水，无本之木